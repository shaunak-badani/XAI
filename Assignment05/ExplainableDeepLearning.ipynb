{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOS6AnK4RvFXSKDU5leDGlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaunak-badani/XAI/blob/Ass5/Assignment05/ExplainableDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIPI 590 - XAI | Assignment #05\n",
        "## Explainable Deep Learning\n",
        "## Shaunak Badani\n",
        "\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/shaunak-badani/XAI/blob/main/Assignment05/ExplainableDeepLearning.ipynb)\n",
        "\n",
        "> This notebook tests a hypothesis on the IMDB dataset using Integrated gradients, and then shows the output."
      ],
      "metadata": {
        "id": "6a7j2u-cjugI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alibi[tensorflow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3HdfTvkJLi",
        "outputId": "e48fc153-82f1-44bf-b887-c90934f58eea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: alibi[tensorflow] in /usr/local/lib/python3.11/dist-packages (0.9.6)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (1.26.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (1.6.1)\n",
            "Requirement already satisfied: spacy<4.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.7.5)\n",
            "Requirement already satisfied: blis<0.8.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (0.7.11)\n",
            "Requirement already satisfied: scikit-image<0.23,>=0.17.2 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (0.22.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (2.32.3)\n",
            "Requirement already satisfied: Pillow<11.0,>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (10.4.0)\n",
            "Requirement already satisfied: attrs<24.0.0,>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (23.2.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (1.13.1)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (4.12.2)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (0.3.9)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (4.48.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (4.67.1)\n",
            "Requirement already satisfied: tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from alibi[tensorflow]) (2.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.0.0->alibi[tensorflow]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.0.0->alibi[tensorflow]) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (2025.1.31)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.23,>=0.17.2->alibi[tensorflow]) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.23,>=0.17.2->alibi[tensorflow]) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.23,>=0.17.2->alibi[tensorflow]) (2025.1.10)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.23,>=0.17.2->alibi[tensorflow]) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->alibi[tensorflow]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->alibi[tensorflow]) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.5.0)\n",
            "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (4.25.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (2.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (0.5.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (2024.10.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.27.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (3.1.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (2.0.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=2.0.0->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow!=2.6.0,!=2.6.1,<2.15.0,>=2.0.0->alibi[tensorflow]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NJO9JP-huK8",
        "outputId": "8c432cc0-b21b-4903-db7c-e08cb7ab0b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.14.1\n",
            "Eager execution enabled:  True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from alibi.explainers import IntegratedGradients\n",
        "import matplotlib.pyplot as plt\n",
        "print('TF version: ', tf.__version__)\n",
        "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)"
      ],
      "metadata": {
        "id": "Lna1dsVRjX3f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training sequences: {len(x_train)}\")\n",
        "print(f\"Number of testing sequences: {len(x_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq_K-AWmlI4a",
        "outputId": "ea33b3c1-c6e3-4691-e40a-4453f44d81c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sequences: 25000\n",
            "Number of testing sequences: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences such that all sequences have the same length\n",
        "max_length = 100\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = max_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = max_length)"
      ],
      "metadata": {
        "id": "EA5HWQd3CRVK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "VJFa59lgHP78"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = imdb.get_word_index()\n",
        "reverse_index = {value: key for (key, value) in index.items()}"
      ],
      "metadata": {
        "id": "3bh9uYjTlOgd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sentence(x, reverse_index):\n",
        "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])"
      ],
      "metadata": {
        "id": "bSKC4GMS5y3m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_sentence(x_test[50], reverse_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "JpuNBs4GG63e",
        "outputId": "e1a2e302-7879-4bf6-a4d0-d8be4f5f8f58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"you into your hearts but really it ended and i felt like i had watched a 5 minute cartoon on kids tv br br i don't have children of my own but when i do i fully intend to show them quality children's movies like the movie toy story and finding UNK even though they are too childish for me these days i can see how they would be of great appeal to young children not so with this appalling attempt at a movie br br oh and one more thing not enough UNK he should have his own movie\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model\n",
        "\n",
        "- We'll be training a 1 dimensional convolutional nueral network, with pooling.\n",
        "\n",
        "- This model will be used with the Integrated Gradients method."
      ],
      "metadata": {
        "id": "PcIFyzTG2uoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_len = max_length\n",
        "features = 10000\n",
        "d_embed = 50\n",
        "inputs = Input(shape = (sequence_len, ), dtype = tf.int32)\n",
        "embedded_sequences = Embedding(features, d_embed)(inputs)\n",
        "\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "out = Conv1D(filters, kernel_size, padding = 'valid', activation = 'relu', strides = 1)(embedded_sequences)\n",
        "out = Dropout(0.4)(out)\n",
        "out = GlobalMaxPooling1D()(out)\n",
        "out = Dense(hidden_dims, activation = 'relu')(out)\n",
        "out = Dropout(0.4)(out)\n",
        "\n",
        "outputs = Dense(2, activation = 'softmax')(out)"
      ],
      "metadata": {
        "id": "N_xutlnklnAg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AdftqFSImIy",
        "outputId": "a4732bbd-c06f-4eaf-c648-815ef1a3e1b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHiBoqIpHVRS",
        "outputId": "b82cc272-04bf-4a5a-824b-e8913a786854"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs, outputs = outputs)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size = 256, epochs = 3, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW3bqFSm4WQP",
        "outputId": "8f6c2135-ee60-4b14-dd57-8a49ad958b81"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "98/98 [==============================] - 34s 330ms/step - loss: 0.5976 - accuracy: 0.6534 - val_loss: 0.4159 - val_accuracy: 0.8191\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 32s 325ms/step - loss: 0.3200 - accuracy: 0.8646 - val_loss: 0.3487 - val_accuracy: 0.8551\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 38s 387ms/step - loss: 0.2127 - accuracy: 0.9198 - val_loss: 0.3365 - val_accuracy: 0.8506\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f9f47cb9290>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrated gradients\n",
        "\n",
        "- Each word in the sequence is mapped to a 50 dimensional vector.\n",
        "- For a 100-length sequence, this will amount to a 100 x 50 dimension matrix.\n",
        "- So  the attribution matrix will also be a matrix of length 100 x 50\n",
        "- If N samples are used, then attribution tensor = (N, 100, 50)"
      ],
      "metadata": {
        "id": "teFxCAdlNNsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = model.layers[1]\n",
        "layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19wu_sgt5rnZ",
        "outputId": "6b8be666-9d71-4e65-d227-1221e76cf222"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x7f9f472c40d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 50\n",
        "method = \"gausslegendre\"\n",
        "internal_batch_size = 100\n",
        "nb_samples = 10\n",
        "ig  = IntegratedGradients(model,\n",
        "                          layer=layer,\n",
        "                          n_steps=n_steps,\n",
        "                          method=method,\n",
        "                          internal_batch_size=internal_batch_size)"
      ],
      "metadata": {
        "id": "TtZ2SCheP5Ab"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = x_test[:nb_samples]\n",
        "probabilities = model(test_batch).numpy()\n",
        "preds = probabilities.argmax(axis = 1)\n",
        "explanation = ig.explain(test_batch, baselines = None, target=preds, attribute_to_layer_inputs = False)"
      ],
      "metadata": {
        "id": "_CWT3gwgP6jF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explanation.meta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2qKhUuTP72c",
        "outputId": "5844e37a-f473-4a6f-855c-ccf089cfac04"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'IntegratedGradients',\n",
              " 'type': ['whitebox'],\n",
              " 'explanations': ['local'],\n",
              " 'params': {'target_fn': None,\n",
              "  'method': 'gausslegendre',\n",
              "  'n_steps': 50,\n",
              "  'internal_batch_size': 100,\n",
              "  'layer': 1},\n",
              " 'version': '0.9.6'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explanation.attributions[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT_lc317Qaas",
        "outputId": "b8b6051e-9fd4-43ca-942e-365a8d627c51"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 100, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attrs = explanation.attributions[0]\n",
        "attrs = attrs.sum(axis = 2) # Sum along all dimensions of the vector embedding space"
      ],
      "metadata": {
        "id": "WSHBljDqQy7v"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the attributions"
      ],
      "metadata": {
        "id": "Nv7lUYJNRZvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence_no = 4\n",
        "x_i = test_batch[sample_sentence_no]\n",
        "attrs_i = attrs[sample_sentence_no]\n",
        "pred = preds[sample_sentence_no]\n",
        "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
      ],
      "metadata": {
        "id": "GWlv2yAeRFeQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJk1XTWiSh62",
        "outputId": "2b23d7a1-ee3e-4a84-fffa-80b67980c98c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label =  1: Positive review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "def  hlstr(string, color='white'):\n",
        "    \"\"\"\n",
        "    Return HTML markup highlighting text with the desired color.\n",
        "    \"\"\"\n",
        "    return f\"<mark style=background-color:{color}>{string} </mark>\""
      ],
      "metadata": {
        "id": "jmvt16qwSpKE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colorize(attrs, cmap='PiYG'):\n",
        "    \"\"\"\n",
        "    Compute hex colors based on the attributions for a single instance.\n",
        "    Uses a diverging colorscale by default and normalizes and scales\n",
        "    the colormap so that colors are consistent with the attributions.\n",
        "    \"\"\"\n",
        "    import matplotlib as mpl\n",
        "    cmap_bound = np.abs(attrs).max()\n",
        "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
        "    cmap = mpl.cm.get_cmap(cmap)\n",
        "\n",
        "    # now compute hex values of colors\n",
        "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
        "    return colors"
      ],
      "metadata": {
        "id": "xQpWG5chStcX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = decode_sentence(x_i, reverse_index).split()\n",
        "colors = colorize(attrs_i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PheNtgQKSuth",
        "outputId": "03a5c262-a4db-4d97-a74b-023b92aab4b9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-a4396b7e2a75>:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = mpl.cm.get_cmap(cmap)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(\"\".join(list(map(hlstr, words, colors))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7Bj2YjGPSvmc",
        "outputId": "4d686afa-6060-4370-e1fa-4cb321e93bf9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark style=background-color:#f7f7f6>die </mark><mark style=background-color:#f7f7f6>hard </mark><mark style=background-color:#f7f7f7>mario </mark><mark style=background-color:#f6f7f5>fan </mark><mark style=background-color:#f5f7f3>and </mark><mark style=background-color:#eef6e2>i </mark><mark style=background-color:#dbf0bf>loved </mark><mark style=background-color:#eff6e4>this </mark><mark style=background-color:#f1f6ea>game </mark><mark style=background-color:#f7f7f6>br </mark><mark style=background-color:#f7f7f7>br </mark><mark style=background-color:#f7f6f7>this </mark><mark style=background-color:#f7f7f6>game </mark><mark style=background-color:#fbe7f2>starts </mark><mark style=background-color:#eff6e5>slightly </mark><mark style=background-color:#f4bfdf>boring </mark><mark style=background-color:#f7f7f6>but </mark><mark style=background-color:#f5f7f3>trust </mark><mark style=background-color:#f5f7f3>me </mark><mark style=background-color:#f1f6ea>it's </mark><mark style=background-color:#edf6df>worth </mark><mark style=background-color:#f5f7f2>it </mark><mark style=background-color:#f5f7f3>as </mark><mark style=background-color:#f7f7f6>soon </mark><mark style=background-color:#f3f7ef>as </mark><mark style=background-color:#f7f7f7>you </mark><mark style=background-color:#fbe8f2>start </mark><mark style=background-color:#f9eff4>your </mark><mark style=background-color:#ecf6de>hooked </mark><mark style=background-color:#f4f7f0>the </mark><mark style=background-color:#f5f7f2>levels </mark><mark style=background-color:#f7f7f6>are </mark><mark style=background-color:#e8f5d5>fun </mark><mark style=background-color:#f0f6e7>and </mark><mark style=background-color:#f6f7f5>UNK </mark><mark style=background-color:#f7f7f6>they </mark><mark style=background-color:#f5f7f3>will </mark><mark style=background-color:#f5f7f3>hook </mark><mark style=background-color:#f6f7f5>you </mark><mark style=background-color:#f7f7f7>UNK </mark><mark style=background-color:#f7f7f7>your </mark><mark style=background-color:#f7f7f6>mind </mark><mark style=background-color:#f7f7f6>turns </mark><mark style=background-color:#f7f7f6>to </mark><mark style=background-color:#f7f7f7>UNK </mark><mark style=background-color:#f7f7f7>i'm </mark><mark style=background-color:#f9eef4>not </mark><mark style=background-color:#f8f4f6>kidding </mark><mark style=background-color:#f8f4f6>this </mark><mark style=background-color:#f5f7f2>game </mark><mark style=background-color:#f2f6ec>is </mark><mark style=background-color:#f6f7f5>also </mark><mark style=background-color:#f7f7f7>UNK </mark><mark style=background-color:#f1f6e8>and </mark><mark style=background-color:#dbf0bf>is </mark><mark style=background-color:#b5df82>beautifully </mark><mark style=background-color:#f6f7f5>done </mark><mark style=background-color:#f7f7f6>br </mark><mark style=background-color:#f7f7f7>br </mark><mark style=background-color:#f7f7f7>to </mark><mark style=background-color:#f7f7f7>keep </mark><mark style=background-color:#f9eef4>this </mark><mark style=background-color:#f8f3f6>spoiler </mark><mark style=background-color:#f8f4f6>free </mark><mark style=background-color:#f7f6f7>i </mark><mark style=background-color:#f7f7f7>have </mark><mark style=background-color:#f7f7f6>to </mark><mark style=background-color:#f7f6f7>keep </mark><mark style=background-color:#f7f7f6>my </mark><mark style=background-color:#fbe8f2>mouth </mark><mark style=background-color:#fbe9f2>shut </mark><mark style=background-color:#f7f7f7>about </mark><mark style=background-color:#f7f7f6>details </mark><mark style=background-color:#f7f7f6>but </mark><mark style=background-color:#faecf3>please </mark><mark style=background-color:#fbe7f2>try </mark><mark style=background-color:#f6f7f5>this </mark><mark style=background-color:#f7f7f6>game </mark><mark style=background-color:#f7f7f7>it'll </mark><mark style=background-color:#f7f7f7>be </mark><mark style=background-color:#f6f7f5>worth </mark><mark style=background-color:#f3f7ef>it </mark><mark style=background-color:#f7f7f7>br </mark><mark style=background-color:#f7f7f7>br </mark><mark style=background-color:#edf6df>story </mark><mark style=background-color:#5ea02c>9 </mark><mark style=background-color:#276419>9 </mark><mark style=background-color:#ebf6dc>action </mark><mark style=background-color:#bbe28a>10 </mark><mark style=background-color:#f9f0f5>1 </mark><mark style=background-color:#f7f7f6>it's </mark><mark style=background-color:#f7f7f6>that </mark><mark style=background-color:#f3f7ef>good </mark><mark style=background-color:#f7f7f7>UNK </mark><mark style=background-color:#f5f7f3>10 </mark><mark style=background-color:#f5f7f2>attention </mark><mark style=background-color:#f8f5f6>UNK </mark><mark style=background-color:#faecf3>10 </mark><mark style=background-color:#fbe8f2>average </mark><mark style=background-color:#eda8d1>10 </mark>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RvDFQVBSycJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMsbnxKcTUg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}